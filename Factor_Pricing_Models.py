# -*- coding: utf-8 -*-
"""Session 2 - FactorPricingModels.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uOpVL9DF_LwbWDvxfQTZg0b_8Ts3wWwn

# Asset Pricing Models

## Data
The stocks selected are Apple, Amazon, Google, Facebook, MacDonald, General Motor, Tesla, and Pfizer, . Below code block will get daily adjusted closing price of each stock

We use S&P 500 to represent the market.

As before, we use 'Adj Close' value to represent asset prices
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
plt.rcParams["figure.figsize"] = (12,8)

# %matplotlib inline

import yfinance as yf

start_date = '2013-01-01'
end_date = '2021-12-31'
stocks = ['^GSPC','AAPL','AMZN','GOOGL','FB', 'MCD', 'GM', 'TSLA','PFE']
data = yf.download(stocks, start_date, end_date)
data.head(5)

"""## Visualize """

data['Adj Close']['^GSPC'].plot(figsize=(12,8))

"""### Dataset we use"""

df=data['Adj Close']

df.head(5)

"""### Convert into returns, and drop the nan """

returns = df.pct_change().dropna()

for c in returns.columns.values:
    plt.plot(returns.index, returns[c], lw=3, alpha=0.8,label=c)
    plt.legend(loc='upper right', fontsize=12)
    plt.ylabel('daily returns')
    plt.show()

returns.head(5)

"""# Simple regression
For each stock, we directly run a regression
$$ \tilde{r}_{it}=\alpha_i + \beta_i \tilde{r}_{Mt} +\tilde{\epsilon}_{it}$$

"""

#or statsmodels
import statsmodels.api as sm
alpha_sm=[]
beta_sm=[]

for column in returns.columns[:-1]:
    X=returns['^GSPC']
    Y=returns[column]
    X=sm.add_constant(X)
    capm_model = sm.OLS(Y, X).fit() 
    alpha_sm.append(capm_model.params[0])
    beta_sm.append(capm_model.params[1])

    print('Alpha', column, ": ", capm_model.params[0])
    print('Beta for', column, ": ", capm_model.params[1])
    print(capm_model.summary())

alpha_sm

beta_sm

"""
# Index Model
To run the index model, we need to find the excess return, or return premium.

## Risk free rate

Approximate the risk-free rate with, for example, the 13 Week (3-month) Treasury Bill (Yahoo finance ticker: ^IRX)."""

#1. Define the length of the period in days:
num_days=90
#FIRST METHOD: yahoo|
rf_yf = yf.download('^IRX', start=start_date, end=end_date)

rf_yf.head(5)

rf_yf['Close'].plot(figsize=(12,8))

"""## convert to daily rates"""

rf_yf=rf_yf['Close']/100
rf=(1 + rf_yf*num_days/360)**(1/num_days)-1

rf.round(6)

"""### add to the dataset"""

returns=returns.assign(RiskFree_yf=pd.Series(rf, index=returns.index))

returns.head(6)

returns.dropna(inplace=True)

#SECOND:Federal Reserve Economic Data (FRED) database
import pandas_datareader.data as web
rf_fred = web.DataReader('TB3MS', 'fred', start=start_date, end=end_date)
rf_fred=rf_fred/100
rf_fred=(1 + rf_fred*num_days/360)**(1/num_days)-1
rf_fred.plot(figsize=(12,8))



"""# One factor index model"""

import statsmodels.api as sm 

Y=returns.AMZN-returns.RiskFree_yf
X=returns['^GSPC']-returns.RiskFree_yf
X=sm.add_constant(X, prepend=False)

index_model = sm.OLS(Y,X).fit()

print(index_model.summary())

"""# CAPM with Monthly Returns
## We use AMZN as an example
"""

# Commented out IPython magic to ensure Python compatibility.
# %reset -f
import matplotlib.pyplot as plt
import warnings

plt.style.use('seaborn')
# plt.style.use('seaborn-colorblind') #alternative
plt.rcParams['figure.figsize'] = [12, 8]
plt.rcParams['figure.dpi'] = 300
warnings.simplefilter(action='ignore', category=FutureWarning)

import pandas as pd
import yfinance as yf
import statsmodels.api as sm

risky_asset = 'AMZN'
market_index = '^GSPC'
risk_free='^IRX'
start_date = '2000-01-01'
end_date = '2021-12-31'

df = yf.download([risky_asset, market_index, risk_free],
                 start=start_date,
                 end=end_date,
                 adjusted=True,
                 progress=False)['Adj Close']

df.head(5)

"""# Resample to monthly data and calculate simple returns:"""

X = df.rename(columns={risky_asset:'asset', 
                                    market_index: 'market', risk_free:'rf'}).resample('M').last()


X.head()

X['asset']=X.asset.pct_change()
X['market']=X.market.pct_change()
X.dropna(inplace=True)

"""### Convert 90-day T-Bill rate into onr month rate"""

X['rf']=(1+X['rf']/100/4)**(1/4)-1
X.head(5)

"""### Calculate beta using the covariance approach (without adjusting $r_f$ )
Note: BMO reports do it this way
$$\beta_i = \frac{Cov(\tilde{r}_i, \tilde{r}_M)}{\sigma_M^2} $$

"""

covariance = X.cov().iloc[0,1]
market_variance = X.market.var()
beta = covariance / market_variance
beta

X['asset_ex']=X['asset']-X['rf']
X['market_ex']=X['market']-X['rf']
X

"""# CAPM

## Prepare the input and estimate CAPM as a linear regression:
"""

# separate target
y = X['asset_ex']
X= X['market_ex']
# add constant
X = sm.add_constant(X)

# define and fit the regression model 
capm_model = sm.OLS(y, X).fit()

# print results 
print(capm_model.summary())

"""
# Implementing the Fama-French 3-factor model
1. The market factor (MKT): It measures the excess return of the market
2. The size factor, SMB (Small Minus Big): It measures the excess return of stocks with a small market cap over those with a large market cap.
3. The value factor, HML (High Minus Low): It measures the excess return of value stocks over growth stocks. Value stocks have a high book-to-market ratio, while the growth stocks are characterized by a low ratio.

Due to the popularity of this approach, these factors became collectively known as the Fama-rench Factors, or the Three-Factor Model. They have been widely accepted in both academia and the industry as stock market benchmarks and they are often used to evaluate investment performance."""

import pandas as pd
import yfinance as yf
import statsmodels.formula.api as smf

"""# Download data from prof. French's website:
http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_Factors_CSV.zip

# Define parameters:
"""

risk_asset = 'FB'
market_index = '^GSPC'
start_date = '2013-12-31'
end_date = '2021-12-31'

# load data from csv
factor_df = pd.read_csv(r'C:\Users\wsuo\Python\Data\F-F_Research_Data_Factors.csv', skiprows=3)

# identify where the annual data starts
STR_TO_MATCH = ' Annual Factors: January-December '
indices = factor_df.iloc[:, 0] == STR_TO_MATCH
start_of_annual = factor_df[indices].index[0]

# keep only monthly data
factor_df = factor_df[factor_df.index < start_of_annual]
factor_df.head

"""Rename columns of the DataFrame, set a datetime index and filter by dates:"""

# rename columns
factor_df.columns = ['date', 'mkt', 'smb', 'hml', 'rf']

# convert strings to datetime
factor_df['date'] = pd.to_datetime(factor_df['date'], 
                                   format='%Y%m').dt.strftime("%Y-%m")

# set index
factor_df = factor_df.set_index('date')

# filter only required dates
factor_df = factor_df.loc[start_date:end_date]
factor_df.head

"""# Convert the values to numeric and divide by 100:"""

factor_df = factor_df.apply(pd.to_numeric,errors='coerce').div(100)
factor_df.head()

"""# Download the prices of the risky asset:"""

asset_df = yf.download(risk_asset,
                       start=start_date,
                       end=end_date,
                       adjusted=True,
                       progress=False)

print(f'Downloaded {asset_df.shape[0]} rows of data.')

y = asset_df['Adj Close'].resample('M').last().pct_change().dropna()
y.index = y.index.strftime('%Y-%m')
y.name = 'rtn'
y.head()

"""# Merge the datasets and calculate excess returns"""

ff_data = factor_df.join(y)
ff_data['excess_rtn'] = ff_data.rtn - ff_data.rf

"""# Estimate the three-factor model:"""

ff_model = smf.ols(formula='excess_rtn ~ mkt + smb + hml', 
                   data=ff_data).fit()

# print results 
print(ff_model.summary())

"""# Implementing the rolling three-factor model on a portfolio of assets
Another way to download the Fama-French factors
"""

from pandas_datareader.famafrench import get_available_datasets
import pandas_datareader.data as web

"""# Print available datasets"""

get_available_datasets()

"""## Download the selected dataset:"""

ff_dict = web.DataReader('F-F_Research_Data_Factors', 'famafrench', 
                         start='2014-01-01')
ff_dict.keys()

"""## Inspect the description of the dataset"""

print(ff_dict['DESCR'])

ff_dict[0].head()

ff_dict[1].head()

"""# Implementing the rolling three-factor model on a portfolio of assets"""

import numpy as np
import pandas as pd
import yfinance as yf
import statsmodels.formula.api as smf
import pandas_datareader.data as web
ASSETS = ['AMZN', 'GOOG', 'AAPL', 'MSFT']
WEIGHTS = [0.25, 0.25, 0.25, 0.25]
START_DATE = '2009-12-31'
END_DATE = '2021-12-31'

#Download the factor related data:
df_three_factor = web.DataReader('F-F_Research_Data_Factors', 'famafrench', 
                                 start=START_DATE)[0]
df_three_factor = df_three_factor.div(100)
df_three_factor.index = df_three_factor.index.format()

#Download the prices of risky assets from Yahoo Finance:
asset_df = yf.download(ASSETS,
                       start=START_DATE,
                       end=END_DATE,
                       adjusted=True,
                       progress=False)

print(f'Downloaded {asset_df.shape[0]} rows of data.')

#Calculate the monthly returns on the risky assets:
asset_df = asset_df['Adj Close'].resample('M').last().pct_change().dropna()
# reformat index for joining
asset_df.index = asset_df.index.strftime('%Y-%m')

#Calculate the portfolio returns:
asset_df['portfolio_returns'] = np.matmul(asset_df[ASSETS].values,WEIGHTS)
asset_df.head()

asset_df.plot()

#Merge the datasets:
ff_data = asset_df.join(df_three_factor).drop(ASSETS, axis=1)
ff_data.columns = ['portf_rtn', 'mkt', 'smb', 'hml', 'rf']
ff_data['portf_ex_rtn'] = ff_data.portf_rtn - ff_data.rf
ff_data.head()

"""# Define a function for the rolling n-factor model"""

def rolling_factor_model(input_data, formula, window_size):
    '''
    Function for estimating the Fama-French (n-factor) model using a rolling window of fixed size.
    
    Parameters
    ------------
    input_data : pd.DataFrame
        A DataFrame containing the factors and asset/portfolio returns
    formula : str
        `statsmodels` compatible formula representing the OLS regression  
    window_size : int
        Rolling window length.
    
    Returns
    -----------
    coeffs_df : pd.DataFrame
        DataFrame containing the intercept and the three factors for each iteration.
    '''

    coeffs = []

    for start_index in range(len(input_data) - window_size + 1):        
        end_index = start_index + window_size

        # define and fit the regression model 
        ff_model = smf.ols(
            formula=formula, 
            data=input_data[start_index:end_index]
        ).fit()
   
        # store coefficients
        coeffs.append(ff_model.params)
    
    coeffs_df = pd.DataFrame(
        coeffs, 
        index=input_data.index[window_size - 1:]
    )

    return coeffs_df

"""# Estimate the rolling three-factor model and plot the results"""

MODEL_FORMULA = 'portf_ex_rtn ~ mkt + smb + hml'
results_df = rolling_factor_model(ff_data, 
                                  MODEL_FORMULA, 
                                  window_size=60)
results_df.plot(title = 'Rolling Fama-French Three-Factor model')

"""# Implementing the four- and five-factor models
MOM: "We use six value-weight portfolios formed on size and prior (2-12) returns to construct Mom. The portfolios, which are formed monthly, are the intersections of 2 portfolios formed on size (market equity, ME) and 3 portfolios formed on prior (2-12) return. The monthly size breakpoint is the median NYSE market equity. The monthly prior (2-12) return breakpoints are the 30th and 70th NYSE percentiles.

Mom is the average return on the two high prior return portfolios minus the average return on the two low prior return portfolios,

 	Mom =	1/2 (Small High + Big High) - 1/2(Small Low + Big Low).	 


"""

import pandas as pd
import yfinance as yf
import statsmodels.formula.api as smf
import pandas_datareader.data as web

RISKY_ASSET = 'AMZN'
START_DATE = '1999-12-31'
END_DATE = '2021-12-31'

# three factors 
df_three_factor = web.DataReader('F-F_Research_Data_Factors', 'famafrench', 
                                 start=START_DATE)[0]
df_three_factor.index = df_three_factor.index.format()

# momentum factor
df_mom = web.DataReader('F-F_Momentum_Factor', 'famafrench', 
                        start=START_DATE)[0]
df_mom.index = df_mom.index.format()

# five factors
df_five_factor = web.DataReader('F-F_Research_Data_5_Factors_2x3', 
                                'famafrench', 
                                start=START_DATE)[0]
df_five_factor.index = df_five_factor.index.format()

asset_df = yf.download(RISKY_ASSET,
                       start=START_DATE,
                       end=END_DATE,
                       adjusted=True,
                       progress=False)

print(f'Downloaded {asset_df.shape[0]} rows of data.')

y = asset_df['Adj Close'].resample('M') \
                         .last() \
                         .pct_change() \
                         .dropna()

y.index = y.index.strftime('%Y-%m')
y.name = 'return'

# join all datasets on the index
four_factor_data = df_three_factor.join(df_mom).join(y)

# rename columns
four_factor_data.columns = ['mkt', 'smb', 'hml', 'rf', 'mom', 'rtn']

# divide everything (except returns) by 100
four_factor_data.loc[:, four_factor_data.columns != 'rtn'] /= 100

# convert index to datetime
four_factor_data.index = [pd.to_datetime(x, format='%Y-%m') for x in four_factor_data.index]

# select period of interest
four_factor_data = four_factor_data.loc[START_DATE:END_DATE]

# calculate excess returns
four_factor_data['excess_rtn'] = four_factor_data.rtn - four_factor_data.rf

four_factor_data.head()

"""### Five Factor Model
RMW: profitability factor RMW is the difference between the returns of firms with robust (high) and weak (low) operating profitability;
CMA:  the investment factor CMA is the difference between the returns of firms that invest conservatively and firms that invest aggressively.

"""

# join all datasets on the index
five_factor_data = df_five_factor.join(y)

# rename columns
five_factor_data.columns = ['mkt', 'smb', 'hml', 'rmw', 'cma', 'rf', 'rtn']

# divide everything (except returns) by 100
five_factor_data.loc[:, five_factor_data.columns != 'rtn'] /= 100

# convert index to datetime
five_factor_data.index = [pd.to_datetime(x, format='%Y-%m') for x in five_factor_data.index]

# select period of interest
five_factor_data = five_factor_data.loc[START_DATE:END_DATE]

# calculate excess returns
five_factor_data['excess_rtn'] = five_factor_data.rtn - five_factor_data.rf

five_factor_data.head()

four_factor_model = smf.ols(formula='excess_rtn ~ mkt + smb + hml + mom', 
                            data=four_factor_data).fit()

print(four_factor_model.summary())

five_factor_model = smf.ols(
    formula='excess_rtn ~ mkt + smb + hml + rmw + cma', 
    data=five_factor_data
).fit()

print(five_factor_model.summary())

"""# Appendix:  Preprocessing the data

## Identifying outliers
"""

import pandas as pd 
import yfinance as yf
df = yf.download('AAPL', 
                 start='2000-01-01', 
                 end='2010-12-31',
                 progress=False)

df = df.loc[:, ['Adj Close']]
df.rename(columns={'Adj Close':'adj_close'}, inplace=True)
df['simple_rtn'] = df.adj_close.pct_change()

"""1. Calculate the rolling mean and standard deviation:"""

rolling_window=21
df_rolling = df[['simple_rtn']].rolling(window=rolling_window).agg(['mean', 'std'])
df_rolling.columns = df_rolling.columns.droplevel()

"""2. Join the rolling metrics to the original data:"""

df_outliers = df.join(df_rolling)

"""3. Define a function for detecting outliers:"""

def indentify_outliers(row, n_sigmas=3):
    '''
    Function for identifying the outliers using the 3 sigma rule. 
    The row must contain the following columns/indices: simple_rtn, mean, std.
    
    Parameters
    ----------
    row : pd.Series
        A row of a pd.DataFrame, over which the function can be applied.
    n_sigmas : int
        The number of standard deviations above/below the mean - used for detecting outliers
        
    Returns
    -------
    0/1 : int
        An integer with 1 indicating an outlier and 0 otherwise.
    '''
    x = row['simple_rtn']
    mu = row['mean']
    sigma = row['std']
    
    if (x > mu + n_sigmas * sigma) | (x < mu - n_sigmas * sigma):
        return 1
    else:
        return 0

"""4. Identify the outliers and extract their values for later use:"""

df_outliers['outlier'] = df_outliers.apply(indentify_outliers, 
                                           axis=1)
outliers = df_outliers.loc[df_outliers['outlier'] == 1, 
                           ['simple_rtn']]

"""5. Plot the results"""

ig, ax = plt.subplots()

ax.plot(df_outliers.index, df_outliers.simple_rtn, 
        color='blue', label='Normal')
ax.scatter(outliers.index, outliers.simple_rtn, 
           color='red', label='Anomaly')
ax.set_title("Apple's stock returns")
ax.legend(loc='lower right')

# plt.tight_layout()
# plt.savefig('images/ch1_im9.png')
plt.show()

"""# Stylized facts of asset returns

1. Import the libraries and dwonload the data
"""

import pandas as pd 
import numpy as np
import yfinance as yf
import seaborn as sns 
import scipy.stats as scs
import statsmodels.api as sm
import statsmodels.tsa.api as smt

df = yf.download('^GSPC', 
                 start='1985-01-01', 
                 end='2018-12-31',
                 progress=False)

df = df[['Adj Close']].rename(columns={'Adj Close': 'adj_close'})
df['log_rtn'] = np.log(df.adj_close/df.adj_close.shift(1))
df = df[['adj_close', 'log_rtn']].dropna(how = 'any')

"""### Fact 1 - distribution of returns

1. Calculate the Normal PDF using the mean and standard deviation of the observed returns:
"""

r_range = np.linspace(min(df.log_rtn), max(df.log_rtn), num=1000)
mu = df.log_rtn.mean()
sigma = df.log_rtn.std()
norm_pdf = scs.norm.pdf(r_range, loc=mu, scale=sigma)

"""2. Plot the histogram and the Q-Q Plot"""

fig, ax = plt.subplots(1, 2, figsize=(16, 8))

# histogram
sns.distplot(df.log_rtn, kde=False, norm_hist=True, ax=ax[0])                                    
ax[0].set_title('Distribution of S&P 500 returns', fontsize=16)                                                    
ax[0].plot(r_range, norm_pdf, 'g', lw=2, 
           label=f'N({mu:.2f}, {sigma**2:.4f})')
ax[0].legend(loc='upper left');

# Q-Q plot
qq = sm.qqplot(df.log_rtn.values, line='s', ax=ax[1])
ax[1].set_title('Q-Q plot', fontsize = 16)

# plt.tight_layout()
# plt.savefig('images/ch1_im10.png')
plt.show()

"""3. Print the summary statistics of the log returns"""

jb_test = scs.jarque_bera(df.log_rtn.values)

print('---------- Descriptive Statistics ----------')
print('Range of dates:', min(df.index.date), '-', max(df.index.date))
print('Number of observations:', df.shape[0])
print(f'Mean: {df.log_rtn.mean():.4f}')
print(f'Median: {df.log_rtn.median():.4f}')
print(f'Min: {df.log_rtn.min():.4f}')
print(f'Max: {df.log_rtn.max():.4f}')
print(f'Standard Deviation: {df.log_rtn.std():.4f}')
print(f'Skewness: {df.log_rtn.skew():.4f}')
print(f'Kurtosis: {df.log_rtn.kurtosis():.4f}') 
print(f'Jarque-Bera statistic: {jb_test[0]:.2f} with p-value: {jb_test[1]:.2f}')

"""### Fact 2 - Volatility Clustering"""

df.log_rtn.plot(title='Daily S&P 500 returns', figsize=(10, 6))

plt.show()

"""### Fact 3 - Absence of autocorrelation in returns

1. Define the parameters for creating the Autocorrelation plots
"""

N_LAGS = 50
SIGNIFICANCE_LEVEL = 0.05

"""2. Run the following code to create ACF plot of log returns"""

acf = smt.graphics.plot_acf(df.log_rtn, 
                            lags=N_LAGS, 
                            alpha=SIGNIFICANCE_LEVEL)
plt.show()

"""### Fact 4 - Small and decreasing autocorrelation in squared/absolute returns

fig, ax = plt.subplots(2, 1, figsize=(12, 10))

smt.graphics.plot_acf(df.log_rtn ** 2, lags=N_LAGS, 
                      alpha=SIGNIFICANCE_LEVEL, ax = ax[0])
ax[0].set(title='Autocorrelation Plots',
          ylabel='Squared Returns')

smt.graphics.plot_acf(np.abs(df.log_rtn), lags=N_LAGS, 
                      alpha=SIGNIFICANCE_LEVEL, ax = ax[1])
ax[1].set(ylabel='Absolute Returns',
          xlabel='Lag')
plt.show()

### Fact 5 - Leverage effect

1. Calculate volatility measures as moving standard deviations
"""

f['moving_std_252'] = df[['log_rtn']].rolling(window=252).std()
df['moving_std_21'] = df[['log_rtn']].rolling(window=21).std()

"""2. Plot all the series"""

fig, ax = plt.subplots(3, 1, figsize=(18, 15), 
                       sharex=True)

df.adj_close.plot(ax=ax[0])
ax[0].set(title='S&P 500 time series',
          ylabel='Price ($)')

df.log_rtn.plot(ax=ax[1])
ax[1].set(ylabel='Log returns (%)')

df.moving_std_252.plot(ax=ax[2], color='r', 
                       label='Moving Volatility 252d')
df.moving_std_21.plot(ax=ax[2], color='g', 
                      label='Moving Volatility 21d')
ax[2].set(ylabel='Moving Volatility',
          xlabel='Date')
ax[2].legend()

plt.show()

"""####  SP 500 & VIX"""

df = yf.download(['^GSPC', '^VIX'], 
                 start='1985-01-01', 
                 end='2018-12-31',
                 progress=False)
df = df[['Adj Close']]
df.columns = df.columns.droplevel(0)
df = df.rename(columns={'^GSPC': 'sp500', '^VIX': 'vix'})

df['log_rtn'] = np.log(df.sp500 / df.sp500.shift(1))
df['vol_rtn'] = np.log(df.vix / df.vix.shift(1))
df.dropna(how='any', axis=0, inplace=True)

corr_coeff = df.log_rtn.corr(df.vol_rtn)

ax = sns.regplot(x='log_rtn', y='vol_rtn', data=df, 
                 line_kws={'color': 'red'})
ax.set(title=f'S&P 500 vs. VIX ($\\rho$ = {corr_coeff:.2f})',
       ylabel='VIX log returns',
       xlabel='S&P 500 log returns')

plt.show()